
\documentclass[a4paper]{article}
%Included packages ----------------------------------------------------------%
\usepackage[utf8]{inputenc}                        % utf-8 encoding, æ, ø , å, etc.
\usepackage{a4wide}                          % Adjust margins to better fit A4 format.
\usepackage{array}                           % Matrices.
\usepackage{amsmath}                         % Math symbols, and enhanced matrices.o
\usepackage{amsfonts}                        % Math fonts.
\usepackage{amssymb}                         % Additional symbols.
%\usepackage{wasysym}                        % More additional symbols.
\usepackage{mathrsfs}                        % Most additional symbols.
\usepackage[pdftex]{graphicx}                % Improved inclusion of .pdf-graphics files.
\usepackage{sidecap}                         % Floats with captions to the right/left.
\usepackage{cancel}                          % Visualize cancellations in equations.
\usepackage{enumerate}                       % Change counters (arabic, roman, etc.).
\usepackage{units}                           % Adds better looking fractions (nicefrac).
\usepackage{floatrow}                        % Multi-figure floats.
\usepackage{subfig}                          % Multi-figure floats.
\usepackage{caption}                         % Adds functionality to captions.
\usepackage{bm}                              % Bolded text in math mode.
\usepackage{combinedgraphics}                % Figures; let latex handle the text itself.
\usepackage[framemethod=default]{mdframed}   % Make boxes.
\usepackage{listings}                        % For including source code.
\usepackage[colorlinks]{hyperref}            % Interactive references, colored.
\usepackage{soul}                            % Make vertical bars through text.
\usepackage{nicefrac}                        % Nice fractions with \nicefrac.
\usepackage{mathtools}                       % Underbrackets, overbrackets.
\usepackage{wasysym}                         % \smiley{}-s!
\usepackage{multicol}                        % Multiple text columns.
\usepackage{capt-of}                         % Caption things which are not floats.
%\usepackage[url=false]{biblatex}             % Citations (made easy).
\usepackage{dsfont}
\usepackage{booktabs}                        % Tables
\usepackage{tabularx}
\usepackage{array}
\usepackage{multirow}% http://ctan.org/pkg/multirow
\usepackage{hhline}% http://ctan.org/pkg/hhline
\usepackage{siunitx}
\usepackage[version=4]{mhchem}
\usepackage{relsize}  % Resize parts of equations
\usepackage[backend=biber,url=false]{biblatex}
\usepackage{mdframed}
\usepackage{tikz}
\usetikzlibrary{matrix}




% Differentials -------------------------------------------------------------- %
\newcommand{\dt}{\,\mathrm{d}t}
\newcommand{\dx}{\,\mathrm{d}x}
\newcommand{\dr}{\,\mathrm{d}r}

% Derivatives ---------------------------------------------------------------- %
\newcommand{\der} [2]{\frac{\mathrm{d} #1}{\mathrm{d} #2}}   % Derivative.
\newcommand{\pder}[2]{\frac{\partial   #1}{\partial   #2}}   % Partial derivative.

% Matrices ------------------------------------------------------------------- %
\newcommand{\mat} [2]{\begin{matrix}[#1]  #2 \end{matrix}}   % Nothing enclosing it.
\newcommand{\pmat}[2]{\begin{pmatrix}[#1] #2 \end{pmatrix}}  % Enclosing parentheses.
\newcommand{\bmat}[2]{\begin{bmatrix}[#1] #2 \end{bmatrix}}  % Enclosing square brackets.
\newcommand{\vmat}[2]{\begin{vmatrix}[#1] #2 \end{vmatrix}}  % Enclosing vertical bars.
\newcommand{\Vmat}[2]{\begin{Vmatrix}[#1] #2 \end{Vmatrix}}  % Enclosing double bars.

% Number sets ---------------------------------------------------------------- %
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}

% Manually set alignment of rows / columns in matrices (mat, pmat, etc.) ----- %
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

% References ----------------------------------------------------------------- %
\newcommand{\Fig}[1]{Fig.\ \ref{fig:#1}}
\newcommand{\fig}[1]{Fig.\ \ref{fig:#1}}
\newcommand{\eq} [1]{Eq.\ (\ref{eq:#1})}
\newcommand{\Eq} [1]{Eq.\ (\ref{eq:#1})}
\newcommand{\tab}[1]{Table \ref{tab:#1}}
\newcommand{\Tab}[1]{Table \ref{tab:#1}}

% Paragraph formatting ------------------------------------------------------- %
\setlength{\parindent}{5.5mm}
\setlength{\parskip}  {0mm}

% Source code listings ------------------------------------------------------- %
\definecolor{commentGreen}{RGB}{34,139,34}
\definecolor{keywordBlue}{RGB}{0,0,255}
\definecolor{stringPurple}{RGB}{160,32,240}
\lstset{language=matlab}
\lstset{basicstyle=\ttfamily\small}
\lstset{frame=single}
\lstset{stringstyle=\color{stringPurple}}
\lstset{keywordstyle=\color{keywordBlue}}
\lstset{commentstyle=\color{commentGreen}}
\lstset{morecomment=[l][\color{commentGreen}\bfseries]{\%\%}}
\lstset{showspaces=false}
\lstset{showstringspaces=false}
\lstset{showtabs=true}
\lstset{columns=fixed}
\lstset{breaklines}
\lstset{literate={~} {$\sim$}{1}}
\lstset{numbers=left}              
\lstset{stepnumber=1}
\renewcommand{\ttdefault}{pcr}
\lstdefinestyle{prt}{frame=none,basicstyle=\ttfamily\small}

% Convenient shorthand notation ---------------------------------------------- %
\newcommand{\nn}{\nonumber}
\newcommand{\e}[1]{\cdot10^{#1}}
\renewcommand{\i}{\hat{\imath}}
\renewcommand{\j}{\hat{\jmath}}
\renewcommand{\k}{\hat{k}}

% Caption position of tables at the top -------------------------------------- %
\floatsetup[table]{capposition=top}

% Black frame with white background ------------------------------------------ %
\newmdenv[linecolor=black,backgroundcolor=white]{exframe}

% Including vector drawings from inkscape ------------------------------------ %
\newenvironment{combFig}[5]{
  \begin{figure}[#1] 
    \centering 
    \includecombinedgraphics[vecscale=#2, keepaspectratio]{#3} 
    \caption{#4 \label{#5}}
  \end{figure}
  }

  {
}

% Including pdf graphics ----------------------------------------------------- %
\newenvironment{pdfFig}[5]{
  \begin{figure}[#1] 
    \centering 
    \includegraphics[width= #2]{#3} 
    \caption{#4 \label{#5}}
  \end{figure}
  }

  {
}

% Exercise and subexercise counters ------------------------------------------ %
\newcounter{excounter}
\renewcommand\theexcounter{\arabic{excounter}}
\newcommand\exlabel{\theexcounter}
\setcounter{excounter}{1}

\newcounter{subexcounter}
\renewcommand\thesubexcounter{\arabic{subexcounter}}
\newcommand\subexlabel{\thesubexcounter}
\setcounter{subexcounter}{1}

% Environments for exercises ------------------------------------------------- %
\newenvironment{exercise}[1]{
  \subsection*{Exercise \theexcounter: #1}
  \setcounter{subexcounter}{1}                      % Reset the subexercise counter to a.
  \addcontentsline{toc}{section}{\theexcounter: #1} % Add the exercise to TOC
  }
      % Exercise text.
  {
  \stepcounter{excounter}                           % Add one to the exercise counter.
  \newpage
}

% Environment for subexercises ----------------------------------------------- %
\newenvironment{subexercise}{
  \begin{exframe}
    \begin{itemize}  \setlength{\itemindent}{1cm}
      \item[{\bf Exercise \thesubexcounter}] 
	}
	  % Subexercise text.
	{
    \end{itemize}
  \end{exframe}
  \stepcounter{subexcounter}                        % Add one to the exercise counter.
}

% Environment for proofs ----------------------------------------------------- %
\newenvironment{proof}[2]{
  \begin{exframe}
    \begin{itemize}  \setlength{\itemindent}{0.6cm}
      \item[{\bf #1} {\bf #2}] 
	}
	  % Subexercise text.
	{
    \end{itemize}
  \end{exframe}
}

% Environment for answers ---------------------------------------------------- %
\newenvironment{answer}{}{}

% Set bibliography file and path for images.
%\bibliography{references/fys4180ref.bib}
\graphicspath{{./images/}}
\newcommand{\includepdfgraphics}[2]{\includecombinedgraphics[#1]{./images/#2}}


\graphicspath{{/Users/morten/Documents/Master/Master/Figures/}}


% Title
\title{}
\date{}
\author{}
% ---------------------------------------------------------------------------- %
% ---------------------------------------------------------------------------- %

\newcommand{\comment}[1]{\ignorespaces}
\addbibresource{/Users/morten/Documents/Master/Master/ref.bib}
%\bibliography{/Users/morten/Documents/Master/Master/ref.bib}%{}
%\bibliographystyle{plain}
\begin{document}


\renewcommand{\R}{{\bf R}}
\renewcommand{\r}{{\bf r}}
\newcommand{\p}{{\bf p}}
\newcommand{\q}{{\bf q}}
\renewcommand{\H}{\mathcal{H}}
\newcommand{\psit}{\left|\psi(t)\right\rangle}



%Atomic Reference Data for Electronic Structure Calculations \url{http://math.nist.gov/DFTdata/atomdata/node4.html}


\section{Density functional theory}
%\subsection{Intro and motivation}
Because the wave function is such an unbelievably complicated function, depending on $4N$ degrees of freedom (of which $3N$ are spatial coordinates), it is natural to ask the question: Is it possible to represent the state of an electronic system in a more succinct way? A natural candidate for such an entity is the electronic number density, $\rho(\r)$, which we will mostly refer to as simply \emph{the density}. It would be remarkable if we could deal with enormously complex quantum mechanical systems by means of a function depending only on three spatial coordinates and spin(!) \cite{kryachko} \comment{p163}.. 

It turns out that exactly this is possible. There is a one-to-one correspondance between the ground state density, $\rho_0(\r)$, and the external potential (up to an additive constant) and thus also the Hamiltonian \cite{toulouse}\comment{p5}. Since the Hamiltonian uniquely determines all properties of a quantum mechanical system, we can in principle determine all the information in the many-body wave function (of the ground state and \emph{all} excited states) from the ground state density alone \cite{martin}\comment{p119}. The fact that the density can be determined from the wave function is almost trivially true, but that the converse is true is the content of the Hohenberg-Kohn theorems. 

However, the theorems of Hohenberg and Kohn guarantee only the existence and uniqueness of an \emph{energy functional}, $E[\rho]$, which can be used to determine the energy from the density. Without knowing the form of $E[\rho]$ and a computational scheme for calculating it, we are still no closer to being able to use the electron density as the basic variable in electronic structure calculations. This is where the Kohn-Sham ansatz comes in, making it possible for us to calculate structure properties of electronic systems by essentially solving a different system\----a non-interacting system with the electrons moving in an effective potential which by construction yields the same ground state density as the original system. 

We will begin our discussion of {\bf Density functional theory} (DFT [sometimes prepended KS, making it Kohn-Sham density functional theory \{KS-DFT\}]) by considering the theoretical framework and the Hohenberg-Kohn theorems. Then we will consider the Kohn-Sham ansatz and how DFT calculations are performed in practice.


\subsection{The Hohenberg-Kohn theorems}
Recall from ((Born-oppenheimer section)) that the \emph{electronic} Hamiltonian under the Born-Oppenheimer approximation takes the form
\begin{align}
\hat H &= -\frac{1}{2}\sum_{i=1}^N\nabla^2_i + \sum_{i=1}^N\sum_{j=i+1}^N \frac{1}{|\r_i-\r_j|} - \sum_{i=1}^N\sum_{A=1}^M \frac{Z_A}{|\r_i-\r_A|}.
\end{align}
We will in the following relabel the last term, and define
\begin{align}
\sum_{i=1}^{N}\sum_{A=1}^M \frac{-Z_A}{|\r_i-\r_A|} &\equiv \hat V_\text{ext}.
\end{align}
Since the first two terms of the Hamiltonian are the same for any system of $N$ electrons, the external potential term $\hat V_\text{ext}$ completely fixes the electronic Hamiltonian as a whole. In fixing $\hat H$, we also fix the spectrum and so the ground state and all its derived properties are determined by $N$ and $\hat V_\text{ext}$ alone \cite{yangparr}\comment{p51}. One such property is of course the ground state electronic density.

In the following, we will denote by $v(\r)$ the spatial (position basis) representation of the external potential $\hat V_\text{ext}$

\subsubsection*{The first Hohenberg-Kohn theorem}
\begin{figure}
\begin{center}
\begin{tikzpicture}
  \matrix (m)[
    matrix of math nodes,
    nodes in empty cells,
    minimum width=width("998888"),
  ] {
  \hat V_\text{ext}(\r) &  \mathlarger{\mathlarger{\xleftarrow{\text{Hohenberg-Kohn}}}} & \rho_0(\r) \\
& & \\
\mathlarger{\mathlarger{\downarrow}} & & \mathlarger{\mathlarger{\uparrow}} \\
& & \\
\hat H & \mathlarger{\mathlarger{\xrightarrow{\text{Schrödinger equation}}}} & \Psi(\R) \\
};
  \draw (-4,-2) -- (4,-2);
  \draw (-4,-2) -- (-4,2);
  \draw (4,-2) -- (4,2);
  \draw (-4,2) -- (4,2);
\end{tikzpicture}
\caption{Schematic representation of the Hohenberg-Kohn theorems. Knowing the external potential fixes the Hamiltonian, from which we can extract the spectrum. The ground state density may then be extracted from the ground state wave function. The Hohenberg-Kohn theorems allows us (in principle) to find the potential if we know only the ground state wave function, making a one-to-one correspondence, $\hat V_\text{ext}(\r)\Leftrightarrow\rho_0(\r)$.  Adapted from a similar figure in \cite{martin}\comment{p112}.  \label{fig:DFT1}}
\end{center}
\end{figure}

As mentioned already, the external potential trivially determines the electron density. The first theorem of Hohenberg and Kohn proves the highly non-trivial converse statement\----the external potential is uniquely determined (up to an additive constant) by the ground state electron density \cite{hohenberg-kohn}. We outline the deceptively simple proof in the following paragraphs.

Consider two potentials, $\hat V_1$ and $\hat V_2$, differing by more than an additive constant, $\hat V_1 \not= \hat V_2 + \text{const}$ and denote the ground state energies of the corresponding Hamiltonians by $E_1$ and $E_2$ respectively. Assume now that the ground state wave functions of the two Hamiltonians are \emph{the same}, $\Psi_1(\R)=\Psi_2(\R)$. Since all parts of the Hamiltonian apart from $\hat V_\text{ext}$ coincide, subtracting the two Schrödinger equations give
\begin{align}
\hat H_1|\Psi\rangle - \hat H_2 |\Psi\rangle = \left(\hat V_1 - \hat V_2\right)|\Psi\rangle &= \left(E_1-E_2\right)|\Psi\rangle.
\end{align}
In terms of the wave functions (projecting the equation onto the position basis) this yields
\begin{align}
\sum_{i=1}^N \big[\hat v_1(\r_i) - \hat v_2(\r_i)\big] \Psi(\r_1,\r_2,\dots,\r_N) &= \left(E_1-E_2\right) \Psi(\r_1,\r_2,\dots,\r_N),
\end{align}
which means $\hat V_1-\hat V_2=\text{const}$, in contradiction with the assumption. 

We proceed thus with $\Psi_1(\R)$ and $\Psi_2(\R)$ neccessarily different. Assume now that $\Psi_1(\R)$ and $\Psi_2(\R)$ have the same ground state electronic density, $\rho_0(\r)$. From the variational principle ((Ref var principle section)), we know that 
\begin{align}
E_1=\big\langle \Psi_1 |\hat H_1 |\Psi_1\big\rangle &< \big\langle \Psi_2 |\hat H_1 |\Psi_2\big\rangle \nn\\
%
&= \big\langle \Psi_2 | \hat H_2 + \hat V_1 - \hat V_2 |\Psi_2\big\rangle \nn\\
%
&= E_2 + \int \,\mathrm{d}^3\r \big[v_1(\r) - v_2(\r) \big] |\Psi_2(\R)|^2 \nn\\
%
\Rightarrow \ \ E_1 &< E_2 + \int \,\mathrm{d}^3\r \big[v_1(\r) - v_2(\r) \big] \rho_0(\r). \label{eq:dft1}
\end{align}
Exchanging the arbitrary indices $1\leftrightarrow2$, gives rise to 
\begin{align}
E_2 &< E_1 + \int \,\mathrm{d}^3\r \big[v_2(\r) - v_1(\r) \big] \rho_0(\r), \label{eq:dft2}
\end{align}
and adding \eq{dft1} from \eq{dft2} gives finally the contradiction $E_1+E_2 < E_1 + E_2$ since the integrals differ only by a sign. But this means that clearly, different $\hat V_\text{ext}$ neccessarily produce differing $\rho_0(\r)$ \cite{toulouse}\comment{p5}.\footnote{As a hands-on example of the first theorem in practice, it is instructive to consider the Coulombic external potential of $M$ stationary nuclei, $\hat V=-\sum_{A=1}^M Z_A/|\r-\r_A|$. In order to uniquely determine the system, we need to know the number of electrons, $N$, the position of the nuclei, $\r_A$, and their charges, $Z_A$. The local maxima of the ground state density coincides perfectly with the nuclei positions. Furthermore, the Kato cusp condition states that at the nuclei ((ref cusp condition section)) $(\partial \bar\rho_0(r_A)/\partial r_A)_{r_A\rightarrow 0}=-2Z_A\bar\rho_0(0)$, where $\bar\rho(r_A)$ denotes the spherical average of density around nucleus $A$ and $r_A=|\r-\r_A|$. This determines $Z_A$ from the ground state density also. Finally, the integral over the density itself gives the number of electrons, $N=\int\,\mathrm{d}^3\r \rho_0(\r)$. 

This is known as E. Bright Wilson's observation \cite{roos}\comment{p92}.}

The statement of the first Hohenberg-Kohn theorem is represented in diagram form in \fig{DFT1}.

\subsubsection*{The second Hohenberg-Kohn theorem}
Since, by the first theorem, the Hamiltonian is determined uniquely by the density, that means the wave function can be considered a functional of the density also, $\Psi[\rho]$. Following the original article by Hohenberg and Kohn\cite{hohenberg-kohn}, we note that this means the kinetic energy operator and the electron-electron interaction operators are also both functionals of the density. These can be combined into the \emph{universal functional}, 
\begin{align}
F[\rho(\r)] \equiv \big\langle \Psi|\hat T + \hat W|\Psi \big\rangle.
\end{align}
A further energy functional, $E_V[\rho]$, can be defined as 
\begin{align}
E_V[\rho(\r)] &\equiv F[\rho(\r)] + \int\mathrm{d}^3\r \,v(\r)\rho(\r),
\end{align}
where $v(\r)$ is the position basis representation of an arbitrary external potential. It is clear that minimizing $E_V[\rho]$ will yield the ground state energy of the system with Hamiltonian $\hat H = \hat T + \hat W + \hat V_\text{ext}$. In the present section we restrict ourselves to densities representing a system of $N$ electrons, i.e. fixing $\int\mathrm{d}^3\r\,\rho(\r)=N$.

We now consider the energy functional evaluated at some other density, $\rho(\r)\not=\rho_0(\r)$, with $\rho_0(\r)$ being the corresponding density of the ground state of $\hat H$, $\rho_0(\r)=\int|\Psi_0(\R)|^2$. The other density, $\rho(\r)$, is taken to be the corresponding ground state density of \emph{some other} external potential, $\hat V_\text{ext}'$. Evaluating the functional gives
\begin{align}
E_V[\rho(\r)] &= \big\langle\Psi|\hat T + \hat W|\Psi\big\rangle + \big\langle\Psi|\hat V_\text{ext}|\Psi\big\rangle = \big\langle \Psi|\hat H|\Psi\big\rangle.
\end{align}
Having established that the external potential is a functional of the density, this gives us now almost trivially that $E_V[\rho]>E_V[\rho_0]$ for any density that is not the one associated with the true ground state corresponding to $\hat V_\text{ext}$ \cite{martin}\comment{p125}. 

\subsubsection*{The way forward}
Essentially, the two Hohenberg-Kohn theorems say that all properties of a electronic quantum mechanical system is uniquely determined by the ground state density alone. Also, a \emph{universal functional} for the energy in terms of the density, valid for any external potential, exists and it attains a global minimum for exactly the true ground state density $\rho_0(\r)$. In the words of Hohenberg and Kohn: "If $F[\rho]$ were a known and sufficiently simple functional of $\rho$, the problem of determining the ground-state energy and density in a given external potential would be rather easy(...)." \cite{hohenberg-kohn} Indeed, all of electronic structure theory would have been \emph{solved} in one fel swoop. 

Predictably, this is not the case. Determination of the universal functional is anything but trivial. In order to make real progress with the approach of considering the electronic density as the primary variable, we turn now to the framework proposed by Kohn and Sham.

\subsection{Kohn-Sham ansatz}
In their seminal 1965 paper \cite{hohenberg-kohn}, Kohn and Sham outlined a way to obtain a set of single electron equations in the density that can be solved self-consitently to obtain the total electronic energy. In order to accomplish this, they consider an auxiliary non-interacting system in place of the original one \cite{martin}\comment{p135}. 
 
Kohn and Sham tell us to consider a non-interacting system for which the ground state density is the same as the ground state density for the interacting system in question. The existance of such a non-interacting system of electrons is far for obvious. In fact, determining neccessary constraints on $\hat V_\text{ext}$ for it to be \emph{non-interacting} $v$\emph{-representable} is still an open question in the theoretical foundations of density functional theory. For almost all real world problems, it is neccessary to simply assume the existance of a non-interacting system for which the ground state density coincides with that of $\hat V_\text{ext}$ \cite{engel}\comment{p71}\cite{martin}\comment{p145}. The assumption that such a non-interacting system exists constitutes the Kohn-Sham ansatz.

We denote the non-interacting Hamiltonian and the corresponding effective potential by $\hat H_s$ and $\hat V_s$, with spatial representation $v_s(\r)$. Since the electrons in this auqiliary system dont feel the coulombic inter-electron force, we know that the \emph{exact} ground state is represented by a Slater determinant filled with the energetically lowest $N$ single electron solutions of the single electron Schrödinger equation \cite{yangparr}\comment{p143}. Note that the Schrödinger equation is by construction separable, since it only involves the kinetic energy operator and a (multiplicative) external potential operator. The one-electron Hamiltonian takes the form
\begin{align}
\hat h_s \psi_i = \left[-\frac{1}{2}\nabla^2 + v_s(\r)\right]\psi_i = \varepsilon_i \psi_i,
\end{align}
with eigenstates $\psi_i$. Since $\hat H_s$ is spin-independent\footnote{If the original Hamiltonian is spin-dependent, the effective potential needs to also carry spin-dependency in order to give the required spin-density. This is a complication we will fully ignore here.} and obviously commutes with $\hat S_z$, we may choose the $\psi_i$ to be products of spatial orbitals and the normalized spinor eigenstates of $\hat S_z$, $\psi_i(\r,\sigma)=\phi_n(\r)\chi(\sigma)$. We note that the quantum number $i$ represents both spatial and spin quantum numbers. This means we can write the exact ground state wave function and the density as 
\begin{align}
\Psi_0(\R)&=\frac{1}{\sqrt{N}}\vmat{cccc}{
\psi_1(\r_1) & \psi_2(\r_1) & \dots & \psi_N(\r_1) \\
\psi_1(\r_2) & \psi_2(\r_2) & \dots & \psi_N(\r_2) \\
\vdots & \vdots & \ddots & \vdots \\
\psi_1(\r_N) & \psi_2(\r_N) & \dots & \psi_N(\r_N)},
\end{align}
with 
\begin{align}
\rho_0(\r) &= \sum_{i=1}^N |\psi_i(\r)|^2 = \sum_\sigma \sum_{n=1}^{N/2} |\phi_n(\r)|^2 = 2\sum_{n=1}^{N/2} |\phi_n(\r)|^2.
\end{align}

In general, the kinetic energy operator as a functional of the density is not known. However, in the auqiliary non-interacting system, we can write down the closed form expression in terms of the $\psi_i$s \cite{yangparr}\comment{p143}:
\begin{align}
T_s[\rho(\r)] &= -\sum_{i=1}^N\big\langle \psi_i|-\frac{1}{2}\nabla_i^2|\psi_i\big\rangle.
\end{align}
Recall that the universal energy functional has the form $F[\rho]=T[\rho]+W[\rho]$, i.e. the sum of the kinetic and the inter-electronic potential functionals. Kohn and Sham now suggest we rewrite $F[\rho]$ in terms of the known non-interacting kinetic energy functional as
\begin{align}
F[\rho]&= T_s[\rho] + J[\rho] + E_\text{xc}[\rho],
\end{align}
where $J[\rho]$ is the classical coulomb interaction functional and $E_\text{xc}[\rho]$ is essentially \emph{everything that is left over} \cite{hohenberg-kohn}. The $J[\rho]$ functional we will shortly see is the functional form of the $\hat J$ operator in the Hartree-Fock approximation ((HF section)), while $E_\text{xc}[\rho]$ is called the exchange-correlation energy and contains the (hopefully small) correction needed for $T_s[\rho]$ in order to make it into $T[\rho]$ and the non-classical part of the electron-electron interaction $\hat W$ \cite{yangparr}\comment{p144}\cite{martin}\comment{p138}. 

The \emph{exact} (recall that the density of the auqiliary system is the same as the original density) energy functional of the fully interacting system can now be written as 
\begin{align}
E[\rho] &= T_s[\rho] + J[\rho] + \int\mathrm{d}^3\r\,\rho(\r)v(\r) + E_\text{xc}[\rho],
\end{align}
where $v(\r)$ is the position basis representation of $\hat V_\text{ext}$. For completeness, we state also the explicit form of the exchange-correlation energy 
\begin{align}
E_\text{xc}[\rho] &= \left(T[\rho] - T_s[\rho] \right) + \left(W[\rho] - J[\rho]\right),
\end{align}
where $W[\rho]=J[\rho]-K[\rho]$ is the functional corresponding to the two-body term in the original Hamiltonian. 

It may seem like we have made no progress at all: We started off with an unknown functional $F[\rho]$, and after introducing the Kohn-Sham ansatz we are still left with an unknown (albeit different) functional, $E_\text{xc}[\rho]$. The exchange-correlation functional, however, may be easier to approximate. Also, we have introduced a separable (by construction) Hamiltonian from which we can extract a set of coupled one-electron Schrödinger equations which we may solve in order to obtain the true ground state density (and in principle all other properties of the system). Note carefully that at this point, no approximations (beyond Born-Oppenheimer and the assumption that the original density was non-interacting $v$-representible) have been made, and so we may consider the preceding results to be exact. This represents a conceptually major difference between DFT and Hartree-Fock theory: The latter is an approximate set of equations which we solve exactly, while DFT constitutes a set of exact equations which we are forced to solve approximately (because we dont know closed form expressions for $E_\text{xc}$).



\subsection{The Kohn-Sham equations}
In the same way Roothan and Hall introduced orbitals to the Hartree-Fock formalism ((ref H-F section)), we now introduce a set of spin-orbitals in the DFT scheme. The single determinantal wave function is constructed from $N$ orthonormal spin-orbitals, $\{\psi_i(\r)\}_{i=1}^N$, where we have absorbed the spin quantum number into the label $i$. In the restricted case, this means that $i$ and $i+1$ are spatially pair-wise identical, with differing spin index. The energy functional can now be written in terms of the orbitals as 
\begin{align}
E[\{\psi_i\}] = \sum_{i=1}^N 
\end{align}



\subsection{Numerical integration grids}
Since the integral of the exchange-correlation potential over the density is rarely (if ever) calculable analytically, we are forced to resort to numerical integration schemes in order to evaluate it. In the one dimensional case, strong and robust integration schemes based on gaussian quadrature integrate any sufficiently \emph{smooth} function to high accuracy using a modest number of integration points \cite{hjorthjensen}\comment{p116}. However, in multiple dimensions, the problem of numerically integrating a multi-variable function is considerably more challenging. Although the philosophy behind is unchanged, the actual application required a lot more thought. Before we begin discussing integrals in density functional theory, we refer the reader to a short introduction to numerical integration in section \ref{numericalintegration} of the appendix. 

The integrals of interest within the framework of density functional theory are integrals over the electronic density. Since we know a priori that the density falls off exponentially in the long range limit (c.f. section \ref{wavefunction}), this reduces to a locally contained integral in some finite and \emph{small} region in space close to the nuclei. Since the potentials are in general functions of the density and its derivatives (which of course also falls off exponentially) we are guaranteed that the exchange-correlation potentials also vanishes exponentially as we move far away from the nuclei. 

\subsubsection{Naive spherical grid}

Voronoi grid: \cite{voronoi1} \cite{voronoi2}
Becke grid: \cite{beckegrid}




\subsection{Local density approximation}
\subsubsection{VWN-LDA}
((YangAndParr, pp275)) ((atomic reference, \url{DFTdata/atomdata/node4.html})) Parametrize the exchange correlation terms: After Vosko, Wilk, and Nusair \cite{vwn}

\textbf{Exchange term}:
\begin{align}
\varepsilon_\text{x} (r_s,\xi) = \varepsilon_\text{x}^P(r_s) + \left[\varepsilon_\text{x}^P(r_s) - \varepsilon_\text{x}^F(r_s) \right] f(\xi),
\end{align}
with 
\begin{align}
r_s &\equiv \left( \frac{3}{4\pi \rho(\r))} \right)^{\nicefrac{1}{3}}, \ \ \ \leftarrow \text{ electron gas parameter} \\
%
\xi &\equiv \frac{\rho_\uparrow(\r) - \rho_\downarrow(\r)}{\rho_\uparrow(\r) + \rho_\downarrow(\r)} \ \ \ \leftarrow \text{ spin polarization}.
\end{align}

\begin{align}
\varepsilon_\text{x}^P(r_s) &= - 3 \left( \frac{9}{32\pi^2} \right)^{\nicefrac{1}{3}} \frac{1}{r_s}, \\
%
\varepsilon_\text{x}^F(r_s) &= - 3(2^{\nicefrac{1}{3}}) \left( \frac{9}{32\pi^2} \right)^{\nicefrac{1}{3}} \frac{1}{r_s},
\end{align}
and
\begin{align}
f(\xi) = \frac{(1+\xi)^{\nicefrac{4}{3}} + (1-\xi)^{\nicefrac{4}{3}} -2}{2(2^{\nicefrac{1}{3}} - 1)}.
\end{align}

In the limit of no spin-polarization (restricted), $\varepsilon_\text{x}$ takes the value
\begin{align}
\varepsilon_\text{x}^{\xi=0}(r_s)= -\frac{3}{2}\left(\frac{3 \rho(\r)}{\pi}\right)^{\nicefrac{1}{3}} \ \ \ \ \ \ \ \text{possibly missing a factor } \frac{1}{2} \text{?}
\end{align}

\textbf{Correlation term}:
\begin{align}
\varepsilon_\text{c}(r_s) &= \frac{A}{2}\left\{ \ln\left(\frac{x}{X(x)}\right) + \frac{2b}{Q}\tan^{-1}\left(\frac{Q}{2x+b}\right) \right.\nn\\
& \ \ \ \ \ \ \ \left.- \frac{bx_0}{X(x_0)} \left[\ln\left(\frac{(x-x_0)^2}{X(x)} \right) + \frac{2(b+2x_0)}{Q}\tan^{-1}\left(\frac{Q}{2x-b} \right) \right]  \right\},
\end{align}
with 
\begin{align}
x &\equiv \sqrt{r_s}, \\
%
X(x) &\equiv x^2+bx+c, \\
%
Q &\equiv \sqrt{4c-b^2}.
\end{align}

For $\xi=0$ we have $A=0.0621814$, $x_0=-0.409286$, $b=13.0720$, and $c=42.7198$.


%\printbibliography



\section{Appendix}
\subsection{Basics of numerical integration\label{numericalintegration}}
\subsubsection{Riemann integral and Riemann integrable functions}
Given a function $f(x)$ and a closed finite subset of $\mathbb{R}$, $[a,b]$ with $a<b$, a \emph{Riemann sum} of $f$ is defined as the sum of values attained on $n$ sub-intervals of $[a,b]$, i.e.
\begin{align}
S_n = \sum_{i=1}^n (x_i-x_{i-1}) \, f_i.
\end{align}
The $x_i$s here define the partitionining into sub-intervals $[x_{i-1},x_i]$ (i.e. $a=x_0<x_1<\dots< x_{n-1}<x_n=b$), while $f_i\equiv f(\xi_i)$ with $\xi_i$ \emph{some} point in sub-interval $i$. 

A sufficient condition for the \emph{Riemann integral} to exist for the function $f$ is that \emph{any} such sum (any choice of $x_i$ [for which $\max_{i}|x_i-x_{i-1}|\rightarrow0$] and $\xi_i$) converge to the same value in the limit $n\rightarrow \infty$ \cite{davis}\comment{p7}. In this case we say
\begin{align}
\lim_{n\rightarrow \infty} S_n = S = \int_a^b f(x)\dx,
\end{align} 
and that $f$ is Riemann integrable.

A less strict, but still sufficient condition is to chose $\overline{f_i}=\max\{f(x):x\in[x_{i-1},x_i]\}$ and $\underline{f_i}=\min\{f(x):x\in[x_{i-1},x_i]\}$ and then only demand that the two sums converge to a common limit \cite{lindstrom}\comment{p366}, 
\begin{align}
\mat{rcccl}{
\displaystyle\lim_{n\rightarrow \infty}\overline{S_n} & = & \displaystyle\lim_{n\rightarrow \infty}\sum_{i=1}^n (x_i-x_{i-1})\overline{f_i} \\
% 
\\[-1em] 
%
& = & \displaystyle\lim_{n\rightarrow \infty}\sum_{i=1}^n (x_i-x_{i-1})\underline{f_i} & = & \displaystyle\lim_{n\rightarrow \infty}\underline{S_n} \\
%
\\[-1.5em] 
% 
&&&=& \displaystyle \int_a^bf(x)\dx.
}\nn
\end{align}

Although easier than checking \emph{every possible} Riemann sum, checking that the two upper and lower sums converge to a common limit is still a somewhat tedious procedure for checking integrability. In fact it turns out that a sufficient condition on $f$ is that it is continous and bounded on $[a,b]$ \cite{davis}\comment{p7}. The latter condition is not neccessary on a finite interval since all continous functions on a closed finite domain are bounded according to the extreme value theorem. However, if we extend the limits of integration to an infinite interval, for example $[0,\infty)$, then the boundedness of $f$ is not guaranteed by the continuity we need to explicitly demand $|f(x)|<\infty$ for all $x\in[a,b]$.

It is easy to see that the converse is \emph{not} true. Any Riemann integrable function is not automatically continous. Take for example the integral over $[0,1]$ with the step function 
\begin{align}
f(x) = \left\{\mat{lcr}{1 & \text{if} & x>1/2 \\ 0 & \text{else} }\right..
\end{align}
Even though the upper and lower Riemann sums both attain the value $1/2$ in the limit $n\rightarrow \infty$ and the function is Riemann integrable, it demonstrably is not continous. A more careful analysis shows that a less strict but sufficient condition on $f$ is that it be continous \emph{almost everywhere} on $[a,b]$ (i.e. continous on all of the interval, except possibly on a subset $C\subset[a,b]$ with measure zero) \cite{mcdonald}\comment{p72}. With this condition, the converse also holds.

\subsubsection{Common approximations to the numerical integral}
Since the Riemann integral is defined in terms of the limit of a sum, numerical approximations to it arise naturally from any scheme for choosing $\xi_i$ and the partitioning. One of the simplest possible approximations is to take the midpoint value of each sub-interval to be $\xi_i$ with a uniform mesh of equispaced $x_i$s. This constitutes the {\bf midpoint rule} \cite{davis}\comment{p52}, 
\begin{align}
I\approx \sum_{i=1}^n f\left(\frac{x_i-x_{i-1}}{2}\right)(x_{i}-x_{i-1})=\Delta x\sum_{i=1}^n f\left(\frac{x_i-x_{i-1}}{2}\right),
\end{align}
where $\Delta x\equiv (x_i-x_{i-1})$ which is the same for all $i$.

Instead of the midpoint, we can use the \emph{average} of the left and right endpoints of the subinterval as $f_i$. Geometrically, this means we are approximating the integral of each sub-interval by the integral over a right trapezoid


\end{document}

% \begin{figure}[p!]
% \centering
% \includegraphics[width=12cm]{<fig>.pdf}
% \caption{\label{fig:1}}
% \end{figure}
 
% \lstinputlisting[firstline=1,lastline=2, float=p!, caption={}, label=lst:1]{<code>.m}

